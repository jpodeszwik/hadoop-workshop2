\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage[polish]{babel}

\begin{document}
Dokumentacja hive:
https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML

Zadania:
\begin{enumerate}
\item Utwórz tabelę apache\_logs. Wrzuć do niej dane z pliku apache\_logs. Możesz skorzystać z polecenia ‘SHOW CREATE TABLE’, żeby namierzyć gdzie hive utworzył bazę na hdfsie i przekopiować plik do katalogu.
\item Utwórz tabelę typu ‘external’ I załaduj do niej takie same dane. Możesz skorzystać z polecenia 'insert into \textit{tabela} select ...'.
\item Zdropuj obie tabele i zobacz co stało się z danymi na hdfsie.
\item Utwórz tabelę w formacie ORC – na końcu polecenia ‘CREATE’ dodaj ‘STORED AS ORC’. Załaduj do niej dane z tabeli apache\_logs (najprościej 'insert into \textit{tabela} select ...'). Spróbuj poleceniem ‘hdfs dfs -cat ...’ wypisać zawartość plików i zobacz, że są binarne.
\item Posumuj content\_length po metodzie (PUT, GET) i zobacz, które requesty zajęły najwięcej transferu. Możesz skorzystać z metody hive’owej split(\textit{string}, \textit{pattern}), żeby wyciągnąć metodę z pola request.
\item Utwórz UDF, który wyciągnie z pola request metodę i spróbuj go użyć zamiast polecenia split. Jara z udfem najprościej umieścić na hdfsie i dodać do hive’a poleceniem CREATE FUNCTION \textit{nazwa\_funkcji} AS \textit{pakiet.NazwaKlasy} USING JAR ‘hdfs://\textit{ścieżka\_na\_hdfs}’
\item Utwórz tabelę partycjonowaną po metodzie i wrzuć do niej dane z tabeli apache\_logs. Skorzystaj z polecenia SET hive.exec.dynamic.partition=true, żeby odblokować dynamiczne wyznaczanie partycji.
\end{enumerate}

\end{document}
